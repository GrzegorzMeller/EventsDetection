{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgT2Rixsa86TsTyplMhKIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrzegorzMeller/EventsDetection/blob/master/NER_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFEgsVt4ehZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6fe968d0-9e0f-4b68-ceba-0eeaa78d9de3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /amd/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxwRlsgtfAoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /amd/My\\ Drive/data_lstm.zip /content/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2KewEXikFPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d280e95e-75bb-4f28-d6b4-59467451aab8"
      },
      "source": [
        "!unzip data_lstm.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data_lstm.zip\n",
            "  inflating: data_lstm/dev.tags.txt  \n",
            "  inflating: data_lstm/dev.words.txt  \n",
            "  inflating: data_lstm/glove.npz     \n",
            "  inflating: data_lstm/test.tags.txt  \n",
            "  inflating: data_lstm/test.words.txt  \n",
            "  inflating: data_lstm/train.tags.txt  \n",
            "  inflating: data_lstm/train.words.txt  \n",
            "  inflating: data_lstm/vocab.chars.txt  \n",
            "  inflating: data_lstm/vocab.tags.txt  \n",
            "  inflating: data_lstm/vocab.words.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc2IkIWShqYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "901b712a-b2c3-44d9-cf05-80a393ba436a"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv1uovCaLCO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50b503c1-4a2a-40d2-808c-cad6f7fcb935"
      },
      "source": [
        "import functools\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "DATADIR = '/content/data_lstm/'\n",
        "\n",
        "# Logging\n",
        "Path('results').mkdir(exist_ok=True)\n",
        "tf.logging.set_verbosity(logging.INFO)\n",
        "handlers = [\n",
        "    logging.FileHandler('results/main.log'),\n",
        "    logging.StreamHandler(sys.stdout)\n",
        "]\n",
        "logging.getLogger('tensorflow').handlers = handlers\n",
        "\n",
        "\n",
        "def parse_fn(line_words, line_tags):\n",
        "    # Encode in Bytes for TF\n",
        "    words = [w.encode() for w in line_words.strip().split()]\n",
        "    tags = [t.encode() for t in line_tags.strip().split()]\n",
        "    assert len(words) == len(tags), \"Words and tags lengths don't match\"\n",
        "    return (words, len(words)), tags\n",
        "\n",
        "\n",
        "def generator_fn(words, tags):\n",
        "    with Path(words).open('r') as f_words, Path(tags).open('r') as f_tags:\n",
        "        for line_words, line_tags in zip(f_words, f_tags):\n",
        "            yield parse_fn(line_words, line_tags)\n",
        "\n",
        "\n",
        "def input_fn(words, tags, params=None, shuffle_and_repeat=False):\n",
        "    params = params if params is not None else {}\n",
        "    shapes = (([None], ()), [None])\n",
        "    types = ((tf.string, tf.int32), tf.string)\n",
        "    defaults = (('<pad>', 0), 'O')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        functools.partial(generator_fn, words, tags),\n",
        "        output_shapes=shapes, output_types=types)\n",
        "\n",
        "    if shuffle_and_repeat:\n",
        "        dataset = dataset.shuffle(params['buffer']).repeat(params['epochs'])\n",
        "\n",
        "    dataset = (dataset\n",
        "               .padded_batch(params.get('batch_size', 20), shapes, defaults)\n",
        "               .prefetch(1))\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    # For serving, features are a bit different\n",
        "    if isinstance(features, dict):\n",
        "        features = features['words'], features['nwords']\n",
        "\n",
        "    # Read vocabs and inputs\n",
        "    dropout = params['dropout']\n",
        "    words, nwords = features\n",
        "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    vocab_words = tf.contrib.lookup.index_table_from_file(\n",
        "        params['words'], num_oov_buckets=params['num_oov_buckets'])\n",
        "    with Path(params['tags']).open() as f:\n",
        "        indices = [idx for idx, tag in enumerate(f) if tag.strip() != 'O']\n",
        "        num_tags = len(indices) + 1\n",
        "\n",
        "    # Word Embeddings\n",
        "    word_ids = vocab_words.lookup(words)\n",
        "    glove = np.load(params['glove'])['embeddings']  # np.array\n",
        "    variable = np.vstack([glove, [[0.]*params['dim']]])\n",
        "    variable = tf.Variable(variable, dtype=tf.float32, trainable=False)\n",
        "    embeddings = tf.nn.embedding_lookup(variable, word_ids)\n",
        "    embeddings = tf.layers.dropout(embeddings, rate=dropout, training=training)\n",
        "\n",
        "    # LSTM\n",
        "    t = tf.transpose(embeddings, perm=[1, 0, 2])\n",
        "    lstm_cell_fw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])\n",
        "    lstm_cell_bw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])\n",
        "    lstm_cell_bw = tf.contrib.rnn.TimeReversedFusedRNN(lstm_cell_bw)\n",
        "    output_fw, _ = lstm_cell_fw(t, dtype=tf.float32, sequence_length=nwords)\n",
        "    output_bw, _ = lstm_cell_bw(t, dtype=tf.float32, sequence_length=nwords)\n",
        "    output = tf.concat([output_fw, output_bw], axis=-1)\n",
        "    output = tf.transpose(output, perm=[1, 0, 2])\n",
        "    output = tf.layers.dropout(output, rate=dropout, training=training)\n",
        "\n",
        "    # CRF\n",
        "    logits = tf.layers.dense(output, num_tags)\n",
        "    crf_params = tf.get_variable(\"crf\", [num_tags, num_tags], dtype=tf.float32)\n",
        "    pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, nwords)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        # Predictions\n",
        "        reverse_vocab_tags = tf.contrib.lookup.index_to_string_table_from_file(\n",
        "            params['tags'])\n",
        "        pred_strings = reverse_vocab_tags.lookup(tf.to_int64(pred_ids))\n",
        "        predictions = {\n",
        "            'pred_ids': pred_ids,\n",
        "            'tags': pred_strings\n",
        "        }\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "    else:\n",
        "        # Loss\n",
        "        vocab_tags = tf.contrib.lookup.index_table_from_file(params['tags'])\n",
        "        tags = vocab_tags.lookup(labels)\n",
        "        log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
        "            logits, tags, nwords, crf_params)\n",
        "        loss = tf.reduce_mean(-log_likelihood)\n",
        "\n",
        "        # Metrics\n",
        "        weights = tf.sequence_mask(nwords)\n",
        "        metrics = {\n",
        "            'acc': tf.metrics.accuracy(tags, pred_ids, weights),\n",
        "            #'precision': precision(tags, pred_ids, num_tags, indices, weights),\n",
        "            #'recall': recall(tags, pred_ids, num_tags, indices, weights),\n",
        "            #'f1': f1(tags, pred_ids, num_tags, indices, weights),\n",
        "        }\n",
        "        for metric_name, op in metrics.items():\n",
        "            tf.summary.scalar(metric_name, op[1])\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.EVAL:\n",
        "            return tf.estimator.EstimatorSpec(\n",
        "                mode, loss=loss, eval_metric_ops=metrics)\n",
        "\n",
        "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            train_op = tf.train.AdamOptimizer().minimize(\n",
        "                loss, global_step=tf.train.get_or_create_global_step())\n",
        "            return tf.estimator.EstimatorSpec(\n",
        "                mode, loss=loss, train_op=train_op)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Params\n",
        "    params = {\n",
        "        'dim': 300,\n",
        "        'dropout': 0.5,\n",
        "        'num_oov_buckets': 1,\n",
        "        'epochs': 25,\n",
        "        'batch_size': 20,\n",
        "        'buffer': 15000,\n",
        "        'lstm_size': 100,\n",
        "        'words': str(Path(DATADIR, 'vocab.words.txt')),\n",
        "        'chars': str(Path(DATADIR, 'vocab.chars.txt')),\n",
        "        'tags': str(Path(DATADIR, 'vocab.tags.txt')),\n",
        "        'glove': str(Path(DATADIR, 'glove.npz'))\n",
        "    }\n",
        "    with Path('results/params.json').open('w') as f:\n",
        "        json.dump(params, f, indent=4, sort_keys=True)\n",
        "\n",
        "    def fwords(name):\n",
        "        return str(Path(DATADIR, '{}.words.txt'.format(name)))\n",
        "\n",
        "    def ftags(name):\n",
        "        return str(Path(DATADIR, '{}.tags.txt'.format(name)))\n",
        "\n",
        "    # Estimator, train and evaluate\n",
        "    train_inpf = functools.partial(input_fn, fwords('train'), ftags('train'),\n",
        "                                   params, shuffle_and_repeat=True)\n",
        "    eval_inpf = functools.partial(input_fn, fwords('test'), ftags('test'))\n",
        "\n",
        "    cfg = tf.estimator.RunConfig(save_checkpoints_secs=120)\n",
        "    estimator = tf.estimator.Estimator(model_fn, 'results/model', cfg, params)\n",
        "    Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)\n",
        "    #hook = tf.contrib.estimator.stop_if_no_increase_hook(\n",
        "    #    estimator, 'f1', 500, min_steps=8000, run_every_secs=120)\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=train_inpf)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_inpf, throttle_secs=120)\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "\n",
        "    # Write predictions to file\n",
        "    def write_predictions(name):\n",
        "        Path('results/score').mkdir(parents=True, exist_ok=True)\n",
        "        with Path('results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
        "            test_inpf = functools.partial(input_fn, fwords(name), ftags(name))\n",
        "            golds_gen = generator_fn(fwords(name), ftags(name))\n",
        "            preds_gen = estimator.predict(test_inpf)\n",
        "            for golds, preds in zip(golds_gen, preds_gen):\n",
        "                ((words, _), tags) = golds\n",
        "                for word, tag, tag_pred in zip(words, tags, preds['tags']):\n",
        "                    f.write(b' '.join([word, tag, tag_pred]) + b'\\n')\n",
        "                f.write(b'\\n')\n",
        "\n",
        "    for name in ['train', 'dev', 'test']:\n",
        "        write_predictions(name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config: {'_model_dir': 'results/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe2bde32978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "Not using Distribute Coordinator.\n",
            "Running training and evaluation locally (non-distributed).\n",
            "Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Calling model_fn.\n",
            "\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "From <ipython-input-5-1fd628593cc1>:75: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "From <ipython-input-5-1fd628593cc1>:89: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/crf/python/ops/crf.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Done calling model_fn.\n",
            "Create CheckpointSaverHook.\n",
            "Graph was finalized.\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Saving checkpoints for 0 into results/model/model.ckpt.\n",
            "loss = 86.90215, step = 1\n",
            "global_step/sec: 4.9099\n",
            "loss = 24.375164, step = 101 (20.369 sec)\n",
            "global_step/sec: 5.19171\n",
            "loss = 15.376857, step = 201 (19.262 sec)\n",
            "global_step/sec: 5.15249\n",
            "loss = 14.959656, step = 301 (19.407 sec)\n",
            "global_step/sec: 5.03605\n",
            "loss = 21.19588, step = 401 (19.857 sec)\n",
            "global_step/sec: 5.28322\n",
            "loss = 14.125071, step = 501 (18.928 sec)\n",
            "global_step/sec: 5.15016\n",
            "loss = 15.122607, step = 601 (19.418 sec)\n",
            "Saving checkpoints for 604 into results/model/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2020-07-13T12:14:29Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-604\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Finished evaluation at 2020-07-13-12:14:30\n",
            "Saving dict for global step 604: acc = 0.87729025, global_step = 604, loss = 12.0521\n",
            "Saving 'checkpoint_path' summary for global step 604: results/model/model.ckpt-604\n",
            "global_step/sec: 4.63117\n",
            "loss = 16.022367, step = 701 (21.592 sec)\n",
            "global_step/sec: 5.2143\n",
            "loss = 13.797874, step = 801 (19.181 sec)\n",
            "global_step/sec: 5.32\n",
            "loss = 13.798098, step = 901 (18.794 sec)\n",
            "global_step/sec: 5.28157\n",
            "loss = 10.675036, step = 1001 (18.937 sec)\n",
            "global_step/sec: 5.30478\n",
            "loss = 10.704045, step = 1101 (18.848 sec)\n",
            "global_step/sec: 5.27757\n",
            "loss = 8.585726, step = 1201 (18.948 sec)\n",
            "Saving checkpoints for 1223 into results/model/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2020-07-13T12:16:29Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-1223\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Finished evaluation at 2020-07-13-12:16:30\n",
            "Saving dict for global step 1223: acc = 0.891147, global_step = 1223, loss = 9.752977\n",
            "Saving 'checkpoint_path' summary for global step 1223: results/model/model.ckpt-1223\n",
            "global_step/sec: 4.6511\n",
            "loss = 10.873297, step = 1301 (21.501 sec)\n",
            "global_step/sec: 5.3551\n",
            "loss = 6.7982216, step = 1401 (18.677 sec)\n",
            "global_step/sec: 5.36933\n",
            "loss = 8.847268, step = 1501 (18.622 sec)\n",
            "global_step/sec: 5.26259\n",
            "loss = 9.903432, step = 1601 (19.007 sec)\n",
            "global_step/sec: 5.27723\n",
            "loss = 8.398989, step = 1701 (18.945 sec)\n",
            "global_step/sec: 5.08137\n",
            "loss = 8.329538, step = 1801 (19.682 sec)\n",
            "Saving checkpoints for 1846 into results/model/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2020-07-13T12:18:29Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-1846\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Finished evaluation at 2020-07-13-12:18:30\n",
            "Saving dict for global step 1846: acc = 0.8925327, global_step = 1846, loss = 8.885835\n",
            "Saving 'checkpoint_path' summary for global step 1846: results/model/model.ckpt-1846\n",
            "global_step/sec: 4.73645\n",
            "loss = 8.280902, step = 1901 (21.113 sec)\n",
            "global_step/sec: 5.31836\n",
            "loss = 5.895145, step = 2001 (18.800 sec)\n",
            "global_step/sec: 5.12997\n",
            "loss = 10.294157, step = 2101 (19.493 sec)\n",
            "global_step/sec: 5.43869\n",
            "loss = 11.564286, step = 2201 (18.387 sec)\n",
            "global_step/sec: 5.53258\n",
            "loss = 9.789345, step = 2301 (18.074 sec)\n",
            "global_step/sec: 5.36997\n",
            "loss = 8.828512, step = 2401 (18.625 sec)\n",
            "Saving checkpoints for 2474 into results/model/model.ckpt.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2020-07-13T12:20:29Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-2474\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Finished evaluation at 2020-07-13-12:20:30\n",
            "Saving dict for global step 2474: acc = 0.89946115, global_step = 2474, loss = 8.252329\n",
            "Saving 'checkpoint_path' summary for global step 2474: results/model/model.ckpt-2474\n",
            "Saving checkpoints for 2480 into results/model/model.ckpt.\n",
            "From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Skip the current checkpoint eval due to throttle secs (120 secs).\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Starting evaluation at 2020-07-13T12:20:33Z\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-2480\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Evaluation [10/100]\n",
            "Finished evaluation at 2020-07-13-12:20:34\n",
            "Saving dict for global step 2480: acc = 0.899923, global_step = 2480, loss = 8.257944\n",
            "Saving 'checkpoint_path' summary for global step 2480: results/model/model.ckpt-2480\n",
            "Loss for final step: 9.113362.\n",
            "Calling model_fn.\n",
            "From <ipython-input-5-1fd628593cc1>:97: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "Done calling model_fn.\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-2480\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-2480\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n",
            "Calling model_fn.\n",
            "Done calling model_fn.\n",
            "Graph was finalized.\n",
            "Restoring parameters from results/model/model.ckpt-2480\n",
            "Running local_init_op.\n",
            "Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB6WANGmIDaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c1ec8de6-80fc-47b6-8136-beec70fff575"
      },
      "source": [
        "!zip -r lstm_results.zip results/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: results/ (stored 0%)\n",
            "  adding: results/model/ (stored 0%)\n",
            "  adding: results/model/eval/ (stored 0%)\n",
            "  adding: results/model/eval/events.out.tfevents.1594642470.bae4fb2c523c (deflated 12%)\n",
            "  adding: results/model/model.ckpt-604.data-00000-of-00001 (deflated 10%)\n",
            "  adding: results/model/checkpoint (deflated 72%)\n",
            "  adding: results/model/model.ckpt-604.index (deflated 40%)\n",
            "  adding: results/model/model.ckpt-2480.data-00000-of-00001 (deflated 10%)\n",
            "  adding: results/model/model.ckpt-2474.data-00000-of-00001 (deflated 10%)\n",
            "  adding: results/model/model.ckpt-1223.meta (deflated 14%)\n",
            "  adding: results/model/model.ckpt-2480.meta (deflated 14%)\n",
            "  adding: results/model/events.out.tfevents.1594642344.bae4fb2c523c (deflated 13%)\n",
            "  adding: results/model/model.ckpt-1846.meta (deflated 14%)\n",
            "  adding: results/model/model.ckpt-1846.data-00000-of-00001 (deflated 10%)\n",
            "  adding: results/model/model.ckpt-2474.index (deflated 40%)\n",
            "  adding: results/model/model.ckpt-1223.data-00000-of-00001 (deflated 10%)\n",
            "  adding: results/model/model.ckpt-1846.index (deflated 40%)\n",
            "  adding: results/model/model.ckpt-2480.index (deflated 40%)\n",
            "  adding: results/model/graph.pbtxt (deflated 59%)\n",
            "  adding: results/model/model.ckpt-2474.meta (deflated 14%)\n",
            "  adding: results/model/model.ckpt-1223.index (deflated 40%)\n",
            "  adding: results/model/model.ckpt-604.meta (deflated 14%)\n",
            "  adding: results/main.log (deflated 74%)\n",
            "  adding: results/params.json (deflated 53%)\n",
            "  adding: results/score/ (stored 0%)\n",
            "  adding: results/score/dev.preds.txt (deflated 77%)\n",
            "  adding: results/score/test.preds.txt (deflated 77%)\n",
            "  adding: results/score/train.preds.txt (deflated 79%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXHh8SpFIm_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r lstm_results.zip /amd/My\\ Drive"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eQGm2g-nyYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}